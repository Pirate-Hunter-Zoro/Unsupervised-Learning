{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3386b974",
   "metadata": {},
   "source": [
    "# Before you begin\n",
    "\n",
    "Download the following jupyter notebook that is part of Jake VanderPlas's Python Data Science Handbook. It will provide exceptional support to help you complete the this part of the assignment.\n",
    "\n",
    "[Pricipal Component Analysis](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.09-Principal-Component-Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb76af",
   "metadata": {},
   "source": [
    "If you are using google colab, uncomment these lines to upload data files to Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a822162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from goodle.colab import files\n",
    "# uploaded = files.upload()\n",
    "# %ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a4b9df",
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "Do not use any other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e5892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import kagglehub\n",
    "from skimage.io import imread_collection\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d17ccd",
   "metadata": {},
   "source": [
    "Fit a Principal component analysis to the following data, then plot the pricipal component vectors scaled to 2 standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "X = np.dot([[1.0,2.0],[0.3, -0.6]], rng.randn(2, 200)).T\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ec1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Principal component analysis to the following data, then plot the pricipal component vectors scaled to 3 standard deviations.\n",
    "pca = None\n",
    "\n",
    "# Plot the principal components\n",
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->', linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "\n",
    "# plot data\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "    v = vector * 3 * np.sqrt(length)\n",
    "    draw_vector(pca.mean_, pca.mean_ + v)\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289dd2a4",
   "metadata": {},
   "source": [
    "Demonstrate PCA dimensionality reduction by using PCA with 1 component to fit the data to the largest principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de93cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA with only 1 component\n",
    "\n",
    "# Transform the data to the first principal component\n",
    "\n",
    "# Transform the data back to its original space\n",
    "\n",
    "# Plot the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f1ea7",
   "metadata": {},
   "source": [
    "The Fashion MNIST datasets contains labelled images of different clothing items. See examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaccc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fashion MNIST dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml(\"Fashion-MNIST\", version=1, return_X_y=True)\n",
    "y = y.astype(int)\n",
    "X = X / 255.0  # scale to [0, 1]\n",
    "print(X.shape, y.shape)\n",
    "fashion_labels = {0: \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\", 5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle boot\"}\n",
    "\n",
    "# Plot some examples from the dataset\n",
    "imgs = X.values.reshape(-1, 28, 28)\n",
    "fig, axes = plt.subplots(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    index = np.where(y == i)[0][0]\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(imgs[index], cmap='binary', \n",
    "               interpolation='nearest', clim=(0,1))\n",
    "    plt.title(f'{fashion_labels[y[index]]} ({y[index]})')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8f69d",
   "metadata": {},
   "source": [
    "Project the images down to 2 dimensions using PCA, then plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e578a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project from 784 to 2 dimensions\n",
    "projected = None\n",
    "\n",
    "# Plot the projected data\n",
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=y, edgecolor='none', alpha=0.25,\n",
    "            cmap=plt.get_cmap('rainbow', 10),\n",
    "            s=3)\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f50d6f5",
   "metadata": {},
   "source": [
    "Plot the change in variance captured by PCA versus the number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ffc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a44906ca",
   "metadata": {},
   "source": [
    "Using the MNIST Fashion dataset, show how you can denoise noisy data using PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c37fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fashion(data):\n",
    "    fig, axes = plt.subplots(3, 10, figsize=(10, 3),\n",
    "                             subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                             gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(data[i].reshape(28, 28),\n",
    "                  cmap='binary', interpolation='nearest',\n",
    "                  clim=(0, 1))\n",
    "plot_fashion(X.values)\n",
    "rng = np.random.default_rng(100)\n",
    "noisy = rng.normal(X, 0.25)\n",
    "plot_fashion(noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a282d0aa",
   "metadata": {},
   "source": [
    "Use PCA to fit 50% of the variance, then plot the filtered clothing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aced995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to fit 50% of the variance\n",
    "filtered = None\n",
    "\n",
    "# Plot the original, noisy, and filtered images\n",
    "plot_fashion(X.values)\n",
    "plot_fashion(noisy)\n",
    "plot_fashion(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01911f9",
   "metadata": {},
   "source": [
    "The pubfig dataset is an image dataset that includes many labeled pictures of famous public figures. Compute eigenfaces for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e9bfc",
   "metadata": {},
   "source": [
    "First, scale the images down to 64x64 and convert them to greyscale. (May take a few minutes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bfa8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"kaustubhchaudhari/pubfig-dataset-256x256-jpg\")\n",
    "path = path + \"\\\\CelebDataProcessed\"\n",
    "\n",
    "# Load the dataset\n",
    "faces = imread_collection(path + \"\\\\*\\\\*.jpg\")\n",
    "print(f\"Number of images: {len(faces)}\")\n",
    "\n",
    "# Downsample and vectorize the images\n",
    "faces = np.array([rgb2gray(resize(img, (64, 64))).ravel()\n",
    "                      for img in faces])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae527e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some of the faces\n",
    "np.random.seed(100)\n",
    "fig, axes = plt.subplots(3, 5, figsize=(10, 6),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    index = np.random.randint(len(faces))\n",
    "    ax.imshow(faces[index].reshape(64, 64), cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d1b118",
   "metadata": {},
   "source": [
    "Compute 150 PCA components. Project the faces down to these components, then perform the inverse to scale them back from the compressed state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the components and projected faces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d7e3f",
   "metadata": {},
   "source": [
    "Plot the PCA component vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e901e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68e5006a",
   "metadata": {},
   "source": [
    "Once again, plot the change in variance captured by PCA versus the number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d049b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d66a7055",
   "metadata": {},
   "source": [
    "Plot a sample of the original images and their reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216eb529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots(2, 10, figsize=(10, 2.5),\n",
    "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i in range(10):\n",
    "    index = np.random.randint(len(faces))\n",
    "    ax[0, i].imshow(faces[index].reshape(64, 64), cmap='binary_r')\n",
    "    ax[1, i].imshow(projected[index].reshape(64, 64), cmap='binary_r')\n",
    "\n",
    "ax[0, 0].set_ylabel('full-dim\\ninput')\n",
    "ax[1, 0].set_ylabel('150-dim\\nreconstruction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curriculum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
